{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HOSSENkhodadadi/Data_Science_Labs_Process_Methods/blob/main/Exercises/3b_Scikitlearn_Classification_N.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' \n",
        "# write some testing codes on transform(), fit_predict()_clustering_ and\n",
        "# fit_transform() _for PCA for transforming data\n",
        "# X.shape = (n_samples, n_fetures)\n",
        "# y_pred.shape = (n_samples)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# max_depth: maximum tree height, Default = None\n",
        "# min_impurity_decrease: split nodes only if impurity decreases above threshold\n",
        "# min_impurity_decrease: dfault: 0.0 \n",
        "clf = DecisionTreeClassifier(max_depth = 10, min_impurity_decrease = 0.01)\n",
        "\n",
        "#Training Part\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Hold-out with Scikit-learn... Default test size is 25%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) \n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "p, r, f1, s = precision_recall_fscore_support(y_test, y_test_pred)\n",
        "\n",
        "# Macro average\n",
        "macro_f1 = f1.mean()\n",
        "\n",
        "# Micro average\n",
        "p, r, f1, s = precision_recall_fscore_support(y_test, y_test_pred, average = 'micro')\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_met = confusion_matrix(y_test, y_test_pred)\n",
        "print(conf_met)\n",
        "'''"
      ],
      "metadata": {
        "id": "s2pTOVRQOhYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# if return_X_y = False it will retrun an object \n",
        "X,y = load_iris(return_X_y = True)"
      ],
      "metadata": {
        "id": "UMf-k9cIS8m_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbRTyvNeOhEK",
        "outputId": "7eca108a-a01d-4217-e4ab-fefbdfa019c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "Vuk_siINo_vp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=.8)"
      ],
      "metadata": {
        "id": "5H2n3qcNpK4Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDUJg7G6pc7n",
        "outputId": "e66c4b01-345e-46ba-8fed-fabf3ac83e38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijS60wbypjBv",
        "outputId": "988616f1-4ba2-4b17-f884-5f727119bcf1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n"
      ],
      "metadata": {
        "id": "OpjAE_q4pmHX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "qEi0ACN6pst3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRLXnORfpv9z",
        "outputId": "b64c9027-1817-4f03-d2f0-1cd7aaf5b2f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "bb6vsNFpIxrx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "Q21qT1KwI9Wi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSdkecHpJNyg",
        "outputId": "ff72eb24-0e73-49ae-a3b6-75c6545aa9ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score(y_pred, y_test, average = \"weighted\")\n",
        "# average can be weighted or None or micro or macro "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjwF_XQ_JZAg",
        "outputId": "e83c15ce-1af9-4f42-c978-9f69168e6c21"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.92"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score(y_pred, y_test, average = None).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-DTyzK6J18Q",
        "outputId": "64ac85a6-f2c0-4edf-f80b-b0e2ac690d34"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333332"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall_score(y_test, y_pred, average = None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc1krvs7KDAI",
        "outputId": "6300763c-af9e-479e-bb4e-494c509da185"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1. , 1. , 0.8])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_pred, y_test, average = None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFrCUOIGKLpp",
        "outputId": "525fda8b-f372-467e-e5c7-a5c840542da5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.85714286, 0.88888889])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lsUhL1-KSTX",
        "outputId": "700dcfeb-ddb8-41c8-dd6f-6c467900a8d4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  0,  0],\n",
              "       [ 0,  9,  0],\n",
              "       [ 0,  3, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Validation method : 1\n",
        "from sklearn.model_selection import KFold\n",
        "# K-Fold with 5 splits\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "for train_indices, test_indices in kfold.split(X, y):\n",
        "  # trian model on X[train_indices], y[train_indices]\n",
        "  # test model on X[test_indices]\n",
        "  #compute an evalution score for the partition\n"
      ],
      "metadata": {
        "id": "9JKDyU-mPI3i"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Validation method : 2\n",
        "# this one gives u an idea of stability\n",
        "# this method does not shuffle so manually shuffle\n",
        "# choose among f1_macro’, 'f1_micro', ‘accuracy’, 'precision_macro'\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "acc = cross_val_score(clf, X, y, cv = 5 , scoring = \"accuracy\")\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMTkPBcPQrAK",
        "outputId": "5462885a-ae9c-4a29-dd5b-cdcf3dc5032c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96666667, 0.96666667, 0.9       , 0.93333333, 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Validation method : 3\n",
        "# they are weighted correctly\n",
        "# data is not shuffled\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "y_pred = cross_val_predict(clf, X, y, cv = 3)\n",
        "acc = accuracy_score( y_test, y_test_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "bEMARr-mRbeb",
        "outputId": "e964de66-9def-4221-e798-93104607bb7d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-51d92502fda4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yumVYQKyQOvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XprP095mOcTF"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "seed = 1234"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkmyA09jOcTH"
      },
      "source": [
        "# 1. Classification and hold-out\n",
        "## 1.1 Load 'abalone' dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWFEwOJrOcTJ"
      },
      "source": [
        "The following are the attribute names, attribute types, the measurement units and a brief description.\n",
        "\n",
        "Your goal is to predict the sex of the abalone, based on the rest of the available information.\n",
        "\n",
        "```\n",
        "Name / Data Type / Measurement Unit / Description\n",
        "-----------------------------\n",
        "Length / continuous / mm / Longest shell measurement\n",
        "Diameter / continuous / mm / perpendicular to length\n",
        "Height / continuous / mm / with meat in shell\n",
        "Whole weight / continuous / grams / whole abalone\n",
        "Shucked weight / continuous / grams / weight of meat\n",
        "Viscera weight / continuous / grams / gut weight (after bleeding)\n",
        "Shell weight / continuous / grams / after being dried\n",
        "Rings / integer / -- / +1.5 gives the age in years \n",
        "Sex / nominal / -- / 2: M, 0: F, and 1: I (infant)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf5bTdwGOcTK"
      },
      "outputs": [],
      "source": [
        "# Load labels\n",
        "df = pd.read_csv(\"abalone.csv\", sep=\" \", header=None, names=[\"length\", \"diameter\", \"height\", \"w_weight\", \"s_weight\", \"v_weight\", \"sh_weight\", \"rings\", \"sex\"])\n",
        "X = ??\n",
        "y_truth = ??\n",
        "\n",
        "# Count items for each class\n",
        "??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPHDtPiBOcTL"
      },
      "source": [
        "## 1.2 Create train and test splits\n",
        "- Use the train_test_split() method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ph-JGY41OcTL"
      },
      "outputs": [],
      "source": [
        "# Separate data into training and test set\n",
        "# Default test_size = 0.25\n",
        "X_train, X_test, y_train, y_test = ??\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0sCLBjBOcTL"
      },
      "source": [
        "## 1.3 Train classifier and make predictions\n",
        "- Use Gaussian Naive Bayes classifier\n",
        "- Random state to make results repeatable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Lg3F6XxOcTM"
      },
      "outputs": [],
      "source": [
        "clf = ??\n",
        "\n",
        "y_test_pred = ??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8Eh3KGPOcTM"
      },
      "source": [
        "## 1.4 Evaluate the results\n",
        "- Evaluation using accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "1hePMY1ZOcTM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "# Compute accuracy\n",
        "acc = ??\n",
        "print(f\"Accuracy = {acc:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmVk5SwXOcTN"
      },
      "source": [
        "- **Accuracy** seems good, but if we look at the scores separately for each class..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "K8npyBWvOcTN"
      },
      "outputs": [],
      "source": [
        "# Precision, recall, f1, support: for each class\n",
        "p, r, f1, support = precision_recall_fscore_support(y_test, y_test_pred)\n",
        "\n",
        "for c in range(p.shape[0]):\n",
        "    print(f\"\\nClass {c}:\")\n",
        "    print(f\"number of items: {support[c]}\")\n",
        "    print(f\"p = {p[c]:.2f}\")\n",
        "    print(f\"r = {r[c]:.2f}\")\n",
        "    print(f\"f1 = {f1[c]:.2f}\")\n",
        "\n",
        "# Macro average f1\n",
        "macro_f1 = ?? \n",
        "    \n",
        "# This score is important when you have class imbalancing\n",
        "print(f\"\\nF1, macro-average: {macro_f1:2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NAxa5JwOcTN"
      },
      "source": [
        "- Accuracy was good because of class imbalancing\n",
        "- The **minority class** (c2) has a very low recall\n",
        "- Indeed, the **macro-averaged** F1 is quite low.\n",
        "\n",
        "### Let's verify this with a confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "QjuZnAbAOcTO"
      },
      "outputs": [],
      "source": [
        "# Build the confusion matrix\n",
        "conf_mat = confusion_matrix(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGdtqJvrOcTO"
      },
      "outputs": [],
      "source": [
        "# Plot the result\n",
        "label_names = np.arange(p.shape[0])\n",
        "conf_mat_df = pd.DataFrame(conf_mat, index = label_names, columns = label_names)\n",
        "conf_mat_df.index.name = 'Actual'\n",
        "conf_mat_df.columns.name = 'Predicted'\n",
        "sns.heatmap(conf_mat_df, annot=True, cmap='GnBu', \n",
        "            annot_kws={\"size\": 16}, fmt='g', cbar=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSdE7cGJOcTO"
      },
      "source": [
        "# 2. Cross-Validation\n",
        "##  2.1 With kfold.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVgu94ZkOcTO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# K-Fold with 5 splits\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "print(\"Scores for each kfold iteration.\")\n",
        "i = 0\n",
        "for train_indices, test_indices in kfold.split(X, y_truth):\n",
        "    # Prepare splits\n",
        "    X_train = ??\n",
        "    y_train = ??\n",
        "    X_test = ??\n",
        "    y_test = ??\n",
        "    \n",
        "    # Train and evaluate\n",
        "    clf = GaussianNB()\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    \n",
        "    # Compute macro average f1\n",
        "    _, _, f1, _ = precision_recall_fscore_support(y_test, y_test_pred)\n",
        "    macro_f1 = f1.mean()\n",
        "    \n",
        "    print(f\"Iteration {i}. macro-f1 = {macro_f1}\")\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnHnLsSHOcTP"
      },
      "source": [
        "## 2.2 With cross_val_score()\n",
        "- Use scoring = 'f1_macro'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbfO6eiQOcTP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9sSJjEZOcTP"
      },
      "outputs": [],
      "source": [
        "clf = GaussianNB()\n",
        "f1_cv = ??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x3BUtvWOcTP"
      },
      "outputs": [],
      "source": [
        "print(f\"Macro-f1 for each iteration: {f1_cv}\")\n",
        "mean_macro_f1 = f1_cv.mean()\n",
        "std_macro_f1 = f1_cv.std() * 2\n",
        "print(f\"Macro-f1 (statistics): {mean_macro_f1:.2f} (+/- {std_macro_f1:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbrXfnQYOcTQ"
      },
      "source": [
        "## 2.3 Leave-One-Out and scoring: cross_val_predict()\n",
        "\n",
        "- The previous approach (average of F1 for each iteration) cannot be used with leave one out. \n",
        "    - Iteration 0: y_test = [1] -> F1?\n",
        "    - Iteration 1: y_test = [0] -> F1?\n",
        "    - ...\n",
        "    - Iteration 2: y_test = [1] -> F1?\n",
        "- When test set has only 1 sample, F1, precision and recall cannot be properly computed.\n",
        "- The following solution trains N models with leave one out, fits them on test data to obtain the vector y_pred (each model predicts 1 single value inside y_pred). Finally, it computes a single score by comparing y_pred with y_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWLIsNofOcTQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "clf = GaussianNB()\n",
        "y_pred = cross_val_predict(clf, X, y_truth, cv=LeaveOneOut())\n",
        "_, _, f1_loo, _ = precision_recall_fscore_support(y_truth, y_pred)\n",
        "macro_f1_loo = f1_loo.mean()\n",
        "print(f\"F1, for each class: {f1_loo}\")\n",
        "print(f\"Macro-f1 = {macro_f1_loo:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}